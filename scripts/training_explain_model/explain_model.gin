from __gin__ import dynamic_registration
import __main__ as train_script
import sbf_modeling
import scripts.training_explain_model.utils as utils
import transformers

# MODE is either "tests" or "deployment"
MODE="tests"
MODEL_DIR = %gin.required

transformers.Seq2SeqTrainingArguments:
    output_dir="_explain_model"
    per_device_train_batch_size=2
    per_device_eval_batch_size=2
    evaluation_strategy="steps"
    eval_steps=100
    logging_steps=100
    gradient_accumulation_steps=8
    num_train_epochs=1
    weight_decay=0.1
    lr_scheduler_type="cosine"
    learning_rate=1e-4
    save_steps=5_000
    generation_max_length=512

sbf_modeling.ExplainModel:
    t5_model_name = "google/flan-t5-large"

sbf_modeling.ExplainModel.train:
    args = @transformers.Seq2SeqTrainingArguments()

utils.get_data:
    mode = %MODE

train_script.train:
    model = @sbf_modeling.ExplainModel()
    train_data = @utils.get_data()
    model_dir = %MODEL_DIR

# inference_script.predict:
#     model = @sbf_modeling.ExplainModel()
#     test_data = @utils.get_data()
#     model_dir = %MODEL_DIR
